{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9thhYuanpkRd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c1eb6db-641a-40cd-8fa1-3c35d4088049"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = 'shakespeare.txt'\n",
        "\n",
        "text = open(path_to_file, 'r').read()\n",
        "\n",
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmW7hq6-c2ni",
        "outputId": "c8da2229-831a-43df-d1cd-1998c0a07394"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(vocab)\n",
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsYA-xS-c6BL",
        "outputId": "e8a26084-7669-4d06-ff30-ebbda1770814"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Step 2: Text Processing\n",
        "\n",
        "# ### Text Vectorization\n",
        "#\n",
        "# We know a neural network can't take in the raw string data, we need to assign numbers to each character. Let's create two dictionaries that can go from numeric index to character and character to numeric index.\n",
        "\n",
        "\n",
        "char_to_ind = {u: i for i, u in enumerate(vocab)}\n",
        "\n",
        "char_to_ind"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdtjOoP8c8IN",
        "outputId": "e16c1e55-fc4d-46a5-d372-009271c18b36"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " '(': 6,\n",
              " ')': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '0': 11,\n",
              " '1': 12,\n",
              " '2': 13,\n",
              " '3': 14,\n",
              " '4': 15,\n",
              " '5': 16,\n",
              " '6': 17,\n",
              " '7': 18,\n",
              " '8': 19,\n",
              " '9': 20,\n",
              " ':': 21,\n",
              " ';': 22,\n",
              " '<': 23,\n",
              " '>': 24,\n",
              " '?': 25,\n",
              " 'A': 26,\n",
              " 'B': 27,\n",
              " 'C': 28,\n",
              " 'D': 29,\n",
              " 'E': 30,\n",
              " 'F': 31,\n",
              " 'G': 32,\n",
              " 'H': 33,\n",
              " 'I': 34,\n",
              " 'J': 35,\n",
              " 'K': 36,\n",
              " 'L': 37,\n",
              " 'M': 38,\n",
              " 'N': 39,\n",
              " 'O': 40,\n",
              " 'P': 41,\n",
              " 'Q': 42,\n",
              " 'R': 43,\n",
              " 'S': 44,\n",
              " 'T': 45,\n",
              " 'U': 46,\n",
              " 'V': 47,\n",
              " 'W': 48,\n",
              " 'X': 49,\n",
              " 'Y': 50,\n",
              " 'Z': 51,\n",
              " '[': 52,\n",
              " ']': 53,\n",
              " '_': 54,\n",
              " 'a': 55,\n",
              " 'b': 56,\n",
              " 'c': 57,\n",
              " 'd': 58,\n",
              " 'e': 59,\n",
              " 'f': 60,\n",
              " 'g': 61,\n",
              " 'h': 62,\n",
              " 'i': 63,\n",
              " 'j': 64,\n",
              " 'k': 65,\n",
              " 'l': 66,\n",
              " 'm': 67,\n",
              " 'n': 68,\n",
              " 'o': 69,\n",
              " 'p': 70,\n",
              " 'q': 71,\n",
              " 'r': 72,\n",
              " 's': 73,\n",
              " 't': 74,\n",
              " 'u': 75,\n",
              " 'v': 76,\n",
              " 'w': 77,\n",
              " 'x': 78,\n",
              " 'y': 79,\n",
              " 'z': 80,\n",
              " '|': 81}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind_to_char = np.array(vocab)\n",
        "ind_to_char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMpUTm22c-F8",
        "outputId": "1cff92fd-765a-4faa-bd53-fc9f689ea902"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1',\n",
              "       '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?',\n",
              "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
              "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
              "       '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j',\n",
              "       'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w',\n",
              "       'x', 'y', 'z', '|'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = np.array([char_to_ind[c] for c in text])\n",
        "encoded_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z6mydKJc_s8",
        "outputId": "81253e76-4281-4667-8d00-a22eaf2c3f4e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1, ..., 50, 59, 73])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We now have a mapping we can use to go back and forth from characters to numerics.\n",
        "\n",
        "sample = text[:20]\n",
        "\n",
        "print(sample)\n",
        "\n",
        "print(encoded_text[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppMQihoXc_1X",
        "outputId": "dfdd3247-a48c-47c0-ec5a-1d6a5512dbfd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                   \n",
            "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Step 3: Creating Batches\n",
        "#\n",
        "# Overall what we are trying to achieve is to have the model predict the next highest probability character given a historical sequence of characters. Its up to us (the user) to choose how long that historic sequence is. Too short a sequence and we don't have enough information (e.g. given the letter \"a\" , what is the next character?) , too long a sequence and training will take too long and most likely overfit to sequence characters that are irrelevant to characters farther out. While there is no correct sequence length choice, you should consider the text itself, how long normal phrases are in it, and a reasonable idea of what characters/words are relevant to each other.\n",
        "\n",
        "\n",
        "print(text[:500])\n",
        "\n",
        "line = \"From fairest creatures we desire increase\"\n",
        "\n",
        "len(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy342XwrdDQJ",
        "outputId": "380d4d9f-34bb-4998-cfc3-5f76fe142577"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "part_stanza = \"\"\"From fairest creatures we desire increase,\n",
        "  That thereby beauty's rose might never die,\n",
        "  But as the riper should by time decease,\"\"\"\n",
        "\n",
        "len(part_stanza)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPvaLR2SdE7k",
        "outputId": "75bd4109-1ff2-49fc-a3e4-25fbbcf14ca0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ### Training Sequences\n",
        "#\n",
        "# The actual text data will be the text sequence shifted one character forward. For example:\n",
        "#\n",
        "# Sequence In: \"Hello my nam\"\n",
        "# Sequence Out: \"ello my name\"\n",
        "#\n",
        "#\n",
        "# We can use the `tf.data.Dataset.from_tensor_slices` function to convert a text vector into a stream of character indices.\n",
        "\n",
        "\n",
        "seq_len = 120\n",
        "\n",
        "total_num_seq = len(text) // (seq_len + 1)\n",
        "\n",
        "total_num_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K1dRm90dHaP",
        "outputId": "6989c6b8-cdcb-40a4-ea0a-50984eae5715"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8665"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Training Sequences\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
        "\n",
        "for i in char_dataset.take(500):\n",
        "    print(ind_to_char[i.numpy()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW8QxwhZdIjr",
        "outputId": "2c64baae-32de-4175-c73b-ab9500385458"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "1\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "r\n",
            "o\n",
            "m\n",
            " \n",
            "f\n",
            "a\n",
            "i\n",
            "r\n",
            "e\n",
            "s\n",
            "t\n",
            " \n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "t\n",
            "u\n",
            "r\n",
            "e\n",
            "s\n",
            " \n",
            "w\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "s\n",
            "i\n",
            "r\n",
            "e\n",
            " \n",
            "i\n",
            "n\n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            "b\n",
            "y\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "u\n",
            "t\n",
            "y\n",
            "'\n",
            "s\n",
            " \n",
            "r\n",
            "o\n",
            "s\n",
            "e\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "n\n",
            "e\n",
            "v\n",
            "e\n",
            "r\n",
            " \n",
            "d\n",
            "i\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "r\n",
            "i\n",
            "p\n",
            "e\n",
            "r\n",
            " \n",
            "s\n",
            "h\n",
            "o\n",
            "u\n",
            "l\n",
            "d\n",
            " \n",
            "b\n",
            "y\n",
            " \n",
            "t\n",
            "i\n",
            "m\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "c\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "H\n",
            "i\n",
            "s\n",
            " \n",
            "t\n",
            "e\n",
            "n\n",
            "d\n",
            "e\n",
            "r\n",
            " \n",
            "h\n",
            "e\n",
            "i\n",
            "r\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "r\n",
            " \n",
            "h\n",
            "i\n",
            "s\n",
            " \n",
            "m\n",
            "e\n",
            "m\n",
            "o\n",
            "r\n",
            "y\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "c\n",
            "o\n",
            "n\n",
            "t\n",
            "r\n",
            "a\n",
            "c\n",
            "t\n",
            "e\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "r\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "e\n",
            "y\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "e\n",
            "e\n",
            "d\n",
            "'\n",
            "s\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "l\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "l\n",
            "a\n",
            "m\n",
            "e\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            "-\n",
            "s\n",
            "u\n",
            "b\n",
            "s\n",
            "t\n",
            "a\n",
            "n\n",
            "t\n",
            "i\n",
            "a\n",
            "l\n",
            " \n",
            "f\n",
            "u\n",
            "e\n",
            "l\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "M\n",
            "a\n",
            "k\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "a\n",
            " \n",
            "f\n",
            "a\n",
            "m\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "w\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "b\n",
            "u\n",
            "n\n",
            "d\n",
            "a\n",
            "n\n",
            "c\n",
            "e\n",
            " \n",
            "l\n",
            "i\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "f\n",
            "o\n",
            "e\n",
            ",\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "w\n",
            "e\n",
            "e\n",
            "t\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "o\n",
            "o\n",
            " \n",
            "c\n",
            "r\n",
            "u\n",
            "e\n",
            "l\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "t\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "a\n",
            "r\n",
            "t\n",
            " \n",
            "n\n",
            "o\n",
            "w\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "o\n",
            "r\n",
            "l\n",
            "d\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "r\n",
            "e\n",
            "s\n",
            "h\n",
            " \n",
            "o\n",
            "r\n",
            "n\n",
            "a\n",
            "m\n",
            "e\n",
            "n\n",
            "t\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "A\n",
            "n\n",
            "d\n",
            " \n",
            "o\n",
            "n\n",
            "l\n",
            "y\n",
            " \n",
            "h\n",
            "e\n",
            "r\n",
            "a\n",
            "l\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "g\n",
            "a\n",
            "u\n",
            "d\n",
            "y\n",
            " \n",
            "s\n",
            "p\n",
            "r\n",
            "i\n",
            "n\n",
            "g\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "W\n",
            "i\n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "u\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The **batch** method converts these individual character calls into sequences we can feed in as a batch. We use seq_len+1 because of zero indexing. Here is what drop_remainder means:\n",
        "#\n",
        "# drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
        "#     whether the last batch should be dropped in the case it has fewer than\n",
        "#     `batch_size` elements; the default behavior is not to drop the smaller\n",
        "#     batch.\n",
        "#\n",
        "\n",
        "\n",
        "sequences = char_dataset.batch(seq_len + 1, drop_remainder=True)\n"
      ],
      "metadata": {
        "id": "FsYzaFyUdKDA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now that we have our sequences, we will perform the following steps for each one to create our target text sequences:\n",
        "#\n",
        "# 1. Grab the input text sequence\n",
        "# 2. Assign the target text sequence as the input text sequence shifted by one step forward\n",
        "# 3. Group them together as a tuple\n",
        "\n",
        "\n",
        "def create_seq_targets(seq):\n",
        "    input_txt = seq[:-1]\n",
        "    target_txt = seq[1:]\n",
        "    return input_txt, target_txt\n",
        "\n",
        "\n",
        "dataset = sequences.map(create_seq_targets)"
      ],
      "metadata": {
        "id": "MG0kU_BOdLoS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_txt, target_txt in dataset.take(1):\n",
        "    print(input_txt.numpy())\n",
        "    print(''.join(ind_to_char[input_txt.numpy()]))\n",
        "    print('\\n')\n",
        "    print(target_txt.numpy())\n",
        "    # There is an extra whitespace!\n",
        "    print(''.join(ind_to_char[target_txt.numpy()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5JHKbMNdM4_",
        "outputId": "a2bbccaa-08d7-4c39-8ee3-ea2bd39ed4bb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 72 69 67  1 60 55 63 72 59 73 74  1 57 72 59 55 74 75 72 59 73\n",
            "  1 77 59  1 58 59 73 63 72 59  1 63 68 57 72 59 55 73 59  8  0  1  1 45\n",
            " 62 55 74  1 74 62 59 72 59 56 79  1 56 59 55 75 74 79  5 73  1 72 69 73\n",
            " 59  1 67 63 61 62 74  1 68 59 76 59 72  1 58 63 59  8  0  1  1 27 75 74]\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But\n",
            "\n",
            "\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 72 69 67  1 60 55 63 72 59 73 74  1 57 72 59 55 74 75 72 59 73  1\n",
            " 77 59  1 58 59 73 63 72 59  1 63 68 57 72 59 55 73 59  8  0  1  1 45 62\n",
            " 55 74  1 74 62 59 72 59 56 79  1 56 59 55 75 74 79  5 73  1 72 69 73 59\n",
            "  1 67 63 61 62 74  1 68 59 76 59 72  1 58 63 59  8  0  1  1 27 75 74  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ### Generating training batches\n",
        "#\n",
        "# Now that we have the actual sequences, we will create the batches, we want to shuffle these sequences into a random order, so the model doesn't overfit to any section of the text, but can instead generate characters given any seed text.\n",
        "\n",
        "\n",
        "# Batch size\n",
        "batch_size = 128\n",
        "\n",
        "# Buffer size to shuffle the dataset so it doesn't attempt to shuffle\n",
        "# the entire sequence in memory. Instead, it maintains a buffer in which it shuffles elements\n",
        "buffer_size = 10000\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27IwvbFwdORI",
        "outputId": "1b4244e7-5807-4ffa-c3be-5b0707697ae4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(128, 120), dtype=tf.int64, name=None), TensorSpec(shape=(128, 120), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Step 4: Creating the Model\n",
        "\n",
        "# This is where YOU will create the model. it needs to start with an embedding layer.\n",
        "#\n",
        "# The embedding layer will serve as the input layer, which essentially creates a lookup table that maps the numbers indices of each character to a vector with \"embedding dim\" number of dimensions. As you can imagine, the larger this embedding size, the more complex the training. This is similar to the idea behind word2vec, where words are mapped to some n-dimensional space. Embedding before feeding straight into the LSTM or GRU usually leads to more realisitic results.\n",
        "\n",
        "\n",
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension. Your choice.\n",
        "embed_dim = 64\n",
        "\n",
        "# Number of RNN units. Your choice. YOU MUST EXPERIMENT WITH THIS NUMBER.\n",
        "rnn_neurons = 1024\n",
        "\n",
        "# Now let's create a function that easily adapts to different variables as shown above.\n"
      ],
      "metadata": {
        "id": "dJqpzW0VdQBI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, GRU"
      ],
      "metadata": {
        "id": "nMNnZ7lHdW8B"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ### Setting up Loss Function\n",
        "#\n",
        "# For our loss we will use sparse categorical crossentropy, which we can import from Keras. We will also set this as logits=True\n",
        "\n",
        "\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "\n",
        "\n",
        "# The reason we need to redefine this is to make sure we are using one hot encoding (from_logits=True)\n",
        "def sparse_cat_loss(y_true, y_pred):\n",
        "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n"
      ],
      "metadata": {
        "id": "K25qmDnEdYFO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
        "    # define your model here...\n",
        "    # don't forget you need an embeddings layer at the beginning\n",
        "    # and a dense layer the size of the vocabulary at the end to generate distributions\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embed_dim,batch_input_shape=[batch_size, None]))\n",
        "    model.add(LSTM(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
        "    # Final Dense Layer to Predict\n",
        "    model.add(Dense(vocab_size))\n",
        "    model.compile(optimizer='adam', loss=sparse_cat_loss, metrics=['accuracy']) \n",
        "    return model"
      ],
      "metadata": {
        "id": "Dduc9HyJdZOo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the model\n",
        "model = create_model(\n",
        "  vocab_size = vocab_size,\n",
        "  embed_dim=embed_dim,\n",
        "  rnn_neurons=rnn_neurons,\n",
        "  batch_size=batch_size)\n",
        "\n",
        "\n",
        "#Train the model\n",
        "epochs = 35\n",
        "model.fit(dataset,epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTZ4pJZpdaQ9",
        "outputId": "75d9b296-f9e7-4b95-9d3a-12f011c90f19"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "67/67 [==============================] - 16s 123ms/step - loss: 3.2557 - accuracy: 0.2241\n",
            "Epoch 2/35\n",
            "67/67 [==============================] - 11s 123ms/step - loss: 2.8111 - accuracy: 0.2786\n",
            "Epoch 3/35\n",
            "67/67 [==============================] - 10s 126ms/step - loss: 2.3048 - accuracy: 0.3585\n",
            "Epoch 4/35\n",
            "67/67 [==============================] - 10s 125ms/step - loss: 2.0743 - accuracy: 0.4080\n",
            "Epoch 5/35\n",
            "67/67 [==============================] - 11s 128ms/step - loss: 1.9126 - accuracy: 0.4485\n",
            "Epoch 6/35\n",
            "67/67 [==============================] - 10s 134ms/step - loss: 1.7790 - accuracy: 0.4848\n",
            "Epoch 7/35\n",
            "67/67 [==============================] - 10s 132ms/step - loss: 1.6679 - accuracy: 0.5144\n",
            "Epoch 8/35\n",
            "67/67 [==============================] - 11s 130ms/step - loss: 1.5855 - accuracy: 0.5366\n",
            "Epoch 9/35\n",
            "67/67 [==============================] - 10s 132ms/step - loss: 1.5202 - accuracy: 0.5535\n",
            "Epoch 10/35\n",
            "67/67 [==============================] - 11s 133ms/step - loss: 1.4671 - accuracy: 0.5668\n",
            "Epoch 11/35\n",
            "67/67 [==============================] - 10s 132ms/step - loss: 1.4222 - accuracy: 0.5783\n",
            "Epoch 12/35\n",
            "67/67 [==============================] - 10s 130ms/step - loss: 1.3848 - accuracy: 0.5883\n",
            "Epoch 13/35\n",
            "67/67 [==============================] - 11s 129ms/step - loss: 1.3529 - accuracy: 0.5963\n",
            "Epoch 14/35\n",
            "67/67 [==============================] - 10s 127ms/step - loss: 1.3235 - accuracy: 0.6035\n",
            "Epoch 15/35\n",
            "67/67 [==============================] - 10s 130ms/step - loss: 1.2977 - accuracy: 0.6103\n",
            "Epoch 16/35\n",
            "67/67 [==============================] - 10s 133ms/step - loss: 1.2733 - accuracy: 0.6163\n",
            "Epoch 17/35\n",
            "67/67 [==============================] - 10s 134ms/step - loss: 1.2508 - accuracy: 0.6228\n",
            "Epoch 18/35\n",
            "67/67 [==============================] - 10s 132ms/step - loss: 1.2308 - accuracy: 0.6280\n",
            "Epoch 19/35\n",
            "67/67 [==============================] - 10s 130ms/step - loss: 1.2099 - accuracy: 0.6336\n",
            "Epoch 20/35\n",
            "67/67 [==============================] - 10s 128ms/step - loss: 1.1905 - accuracy: 0.6389\n",
            "Epoch 21/35\n",
            "67/67 [==============================] - 10s 128ms/step - loss: 1.1721 - accuracy: 0.6438\n",
            "Epoch 22/35\n",
            "67/67 [==============================] - 10s 128ms/step - loss: 1.1511 - accuracy: 0.6500\n",
            "Epoch 23/35\n",
            "67/67 [==============================] - 10s 128ms/step - loss: 1.1332 - accuracy: 0.6551\n",
            "Epoch 24/35\n",
            "67/67 [==============================] - 10s 130ms/step - loss: 1.1115 - accuracy: 0.6616\n",
            "Epoch 25/35\n",
            "67/67 [==============================] - 10s 128ms/step - loss: 1.0913 - accuracy: 0.6676\n",
            "Epoch 26/35\n",
            "67/67 [==============================] - 10s 131ms/step - loss: 1.0708 - accuracy: 0.6739\n",
            "Epoch 27/35\n",
            "67/67 [==============================] - 10s 134ms/step - loss: 1.0496 - accuracy: 0.6812\n",
            "Epoch 28/35\n",
            "67/67 [==============================] - 10s 132ms/step - loss: 1.0280 - accuracy: 0.6879\n",
            "Epoch 29/35\n",
            "67/67 [==============================] - 10s 130ms/step - loss: 1.0055 - accuracy: 0.6957\n",
            "Epoch 30/35\n",
            "67/67 [==============================] - 10s 129ms/step - loss: 0.9810 - accuracy: 0.7037\n",
            "Epoch 31/35\n",
            "67/67 [==============================] - 10s 128ms/step - loss: 0.9578 - accuracy: 0.7114\n",
            "Epoch 32/35\n",
            "67/67 [==============================] - 10s 128ms/step - loss: 0.9322 - accuracy: 0.7206\n",
            "Epoch 33/35\n",
            "67/67 [==============================] - 10s 129ms/step - loss: 0.9077 - accuracy: 0.7286\n",
            "Epoch 34/35\n",
            "67/67 [==============================] - 10s 129ms/step - loss: 0.8815 - accuracy: 0.7377\n",
            "Epoch 35/35\n",
            "67/67 [==============================] - 10s 130ms/step - loss: 0.8556 - accuracy: 0.7476\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f10a01687d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "losses.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZZzvcSmmdd_F",
        "outputId": "7913b494-f916-4f79-b53e-4b61e8bbd742"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       loss  accuracy\n",
              "0  3.255684  0.224126\n",
              "1  2.811103  0.278560\n",
              "2  2.304814  0.358486\n",
              "3  2.074301  0.408006\n",
              "4  1.912637  0.448478"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc00e277-972c-40ac-b8aa-d483e0611bc0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.255684</td>\n",
              "      <td>0.224126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.811103</td>\n",
              "      <td>0.278560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.304814</td>\n",
              "      <td>0.358486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.074301</td>\n",
              "      <td>0.408006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.912637</td>\n",
              "      <td>0.448478</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc00e277-972c-40ac-b8aa-d483e0611bc0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc00e277-972c-40ac-b8aa-d483e0611bc0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc00e277-972c-40ac-b8aa-d483e0611bc0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses[['loss','accuracy']].plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "8Wb4cDGMdfix",
        "outputId": "9fc0db0a-1cd3-4ae1-be3e-2350559abd18"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f10364164d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ax = losses.plot(lw=2, colormap='jet', marker='.', markersize=10, title='Loss and Accuracy trend during training')\n",
        "ax.set_xlabel(\"epoch\")\n",
        "ax.set_ylabel(\"metric\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "__rntk0wdhNj",
        "outputId": "cc78aa82-ee5f-4674-f6a2-3ef1a5d762bf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'metric')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ax.figure.savefig('acc_loss_1024.png')"
      ],
      "metadata": {
        "id": "kHnB25eEdj7I"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "\n",
        "  # Predict off some random batch\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "\n",
        "  # Display the dimensions of the predictions\n",
        "  print(example_batch_predictions.shape, \" <=== (batch_size, sequence_length, vocab_size)\")\n",
        "\n",
        "example_batch_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooB7YxaVdrdq",
        "outputId": "71ad1048-1747-4306-e7fa-dfb2cb8a5eb6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 120, 82)  <=== (batch_size, sequence_length, vocab_size)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 120, 82), dtype=float32, numpy=\n",
              "array([[[ 5.0771520e-02,  4.9719925e+00, -2.5067456e+00, ...,\n",
              "          6.6945702e-01, -5.3531446e+00, -5.7219677e+00],\n",
              "        [ 1.2729785e+01,  1.1408561e+01,  1.7823865e+00, ...,\n",
              "         -1.5041738e+00, -3.6556313e+00, -2.4687054e+00],\n",
              "        [ 5.4900141e+00,  1.2076597e+01, -4.8968215e+00, ...,\n",
              "         -7.2337618e+00, -9.6460838e+00, -4.0692291e+00],\n",
              "        ...,\n",
              "        [ 6.8824277e+00,  1.0099251e+01,  8.9073539e-01, ...,\n",
              "         -1.2072359e+00, -4.6167526e+00, -3.2268946e+00],\n",
              "        [-4.5928717e+00, -9.7304955e-02, -9.6468716e+00, ...,\n",
              "          7.2117698e-01, -3.8801532e+00, -9.5282860e+00],\n",
              "        [ 1.6470909e+00,  4.2039865e-01, -5.9257536e+00, ...,\n",
              "         -5.6388474e-01, -7.3564034e+00, -5.6561689e+00]],\n",
              "\n",
              "       [[-4.8158121e+00, -1.5201204e-01, -8.8673754e+00, ...,\n",
              "         -2.2157853e+00, -4.4665475e+00, -9.1810160e+00],\n",
              "        [ 7.0738149e-01,  4.2211361e+00, -9.3154860e+00, ...,\n",
              "          1.6678293e+00, -6.7125893e+00, -7.8724709e+00],\n",
              "        [-3.4843073e+00,  3.9629104e+00, -3.4493237e+00, ...,\n",
              "          5.4501367e-01, -6.6423483e+00, -5.8440886e+00],\n",
              "        ...,\n",
              "        [-2.9178975e+00,  2.7845354e+00, -4.2629108e+00, ...,\n",
              "          1.5111775e+00, -4.1481819e+00, -5.9170065e+00],\n",
              "        [-6.9690113e+00, -1.0588286e+00, -1.9399196e+00, ...,\n",
              "          2.3557734e+00, -7.0937877e+00, -4.3576727e+00],\n",
              "        [ 1.9254692e+00,  6.7967472e+00,  2.4544847e+00, ...,\n",
              "         -6.1617866e+00, -7.3922324e-01, -4.0782766e+00]],\n",
              "\n",
              "       [[-3.3281195e+00,  2.8104188e+00, -3.1307528e+00, ...,\n",
              "         -1.8157947e+00, -3.8573751e+00, -2.2024596e+00],\n",
              "        [ 1.6355923e+00,  4.2789178e+00, -3.1960315e-01, ...,\n",
              "         -3.8819840e+00, -3.5550191e+00, -2.9981823e+00],\n",
              "        [ 4.4576898e+00,  8.7737217e+00,  2.5716357e+00, ...,\n",
              "         -6.9116360e-01, -4.3739023e+00, -2.6157212e+00],\n",
              "        ...,\n",
              "        [-1.0321534e+01, -4.6435938e+00, -6.9778738e+00, ...,\n",
              "          2.4992843e+00, -5.3570733e+00, -1.0158524e+01],\n",
              "        [-5.9712162e+00, -6.9588482e-01, -5.2274375e+00, ...,\n",
              "         -2.8460171e-02, -2.8593724e+00, -8.7945108e+00],\n",
              "        [ 1.6441476e+00,  8.2625523e+00, -3.0691741e+00, ...,\n",
              "          2.9339197e+00, -4.5801969e+00, -5.3439326e+00]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-6.8732829e+00,  7.6499093e-01, -8.8011436e+00, ...,\n",
              "          1.8764398e+00, -6.7739639e+00, -6.7516990e+00],\n",
              "        [-6.7108951e+00,  4.3270783e+00, -5.0072527e+00, ...,\n",
              "          1.5446579e+00, -5.6647978e+00, -8.7593384e+00],\n",
              "        [-6.2034521e+00, -1.9828504e+00, -6.2777915e+00, ...,\n",
              "          7.2025747e+00,  3.2643912e+00, -8.6175394e+00],\n",
              "        ...,\n",
              "        [ 1.4729850e+00,  7.3989172e+00,  1.4458532e+00, ...,\n",
              "         -7.3830562e+00, -8.1314926e+00, -1.5640854e+00],\n",
              "        [ 6.4605541e+00,  1.5999497e+01, -2.9515228e+00, ...,\n",
              "         -6.5858459e+00, -9.3257027e+00, -7.9010177e-01],\n",
              "        [-6.4923263e+00,  2.4671912e+00, -7.5211992e+00, ...,\n",
              "         -1.2672784e-02, -5.6011486e+00, -5.2419863e+00]],\n",
              "\n",
              "       [[-3.1378829e+00,  3.2008486e+00, -1.0023088e+01, ...,\n",
              "          2.4636409e+00, -6.0280981e+00, -8.8903751e+00],\n",
              "        [-3.8910432e+00,  2.2901385e+00, -5.3074646e+00, ...,\n",
              "          1.8195837e+00, -1.0635813e+01, -3.7872307e+00],\n",
              "        [-2.5062518e+00,  4.1651082e+00, -1.9161723e+00, ...,\n",
              "         -1.7189932e+00, -8.1780434e-01, -4.7974491e+00],\n",
              "        ...,\n",
              "        [-5.4635653e+00,  1.9460416e+00, -8.9492893e+00, ...,\n",
              "          4.0393829e+00, -6.5147281e+00, -8.7437143e+00],\n",
              "        [-3.5746734e+00,  1.7725379e+00, -3.5073028e+00, ...,\n",
              "          4.6350570e+00, -6.0031734e+00, -6.2250500e+00],\n",
              "        [-5.4263639e-01,  3.0739646e+00, -2.9966657e+00, ...,\n",
              "          6.7055717e+00, -7.0666542e+00, -2.7123127e+00]],\n",
              "\n",
              "       [[-2.9626641e+00, -2.6863858e-01, -1.7185241e+00, ...,\n",
              "         -1.1008641e+00, -4.4483976e+00, -3.9943857e+00],\n",
              "        [-2.0620632e+00,  3.6206863e+00, -7.6210504e+00, ...,\n",
              "          3.7566972e-01, -4.9297509e+00, -8.4409828e+00],\n",
              "        [-1.4064457e+00,  2.1555681e+00, -2.0646996e+00, ...,\n",
              "         -4.9526498e-01, -6.0347738e+00, -7.2014518e+00],\n",
              "        ...,\n",
              "        [-9.3565561e-02,  3.2863386e+00, -4.6327171e-01, ...,\n",
              "         -3.2173245e+00, -7.8442836e+00, -2.7588525e+00],\n",
              "        [ 3.1286058e+00,  1.3089493e+01, -1.4412898e+00, ...,\n",
              "         -1.7631924e+00, -8.1316442e+00,  4.0196800e-01],\n",
              "        [-8.5687981e+00,  1.2586037e+00, -1.1260703e+01, ...,\n",
              "         -2.0372739e-01, -1.0182093e+01, -4.0549345e+00]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jogZb7-JdxY2",
        "outputId": "1c91f16b-5e8d-4b50-a0ad-59aef92b2e02"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n",
              "array([[66],\n",
              "       [ 0],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [79],\n",
              "       [ 1],\n",
              "       [77],\n",
              "       [63],\n",
              "       [71],\n",
              "       [73],\n",
              "       [69],\n",
              "       [68],\n",
              "       [ 1],\n",
              "       [74],\n",
              "       [62],\n",
              "       [59],\n",
              "       [ 1],\n",
              "       [61],\n",
              "       [72],\n",
              "       [63],\n",
              "       [73],\n",
              "       [63],\n",
              "       [57],\n",
              "       [63],\n",
              "       [55],\n",
              "       [68],\n",
              "       [ 1],\n",
              "       [58],\n",
              "       [59],\n",
              "       [ 1],\n",
              "       [73],\n",
              "       [79],\n",
              "       [ 1],\n",
              "       [67],\n",
              "       [69],\n",
              "       [77],\n",
              "       [59],\n",
              "       [ 8],\n",
              "       [ 0],\n",
              "       [ 1],\n",
              "       [ 0],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [28],\n",
              "       [68],\n",
              "       [58],\n",
              "       [72],\n",
              "       [79],\n",
              "       [ 1],\n",
              "       [74],\n",
              "       [69],\n",
              "       [75],\n",
              "       [74],\n",
              "       [ 1],\n",
              "       [58],\n",
              "       [59],\n",
              "       [73],\n",
              "       [ 1],\n",
              "       [57],\n",
              "       [69],\n",
              "       [69],\n",
              "       [58],\n",
              "       [59],\n",
              "       [63],\n",
              "       [55],\n",
              "       [70],\n",
              "       [74],\n",
              "       [63],\n",
              "       [69],\n",
              "       [68],\n",
              "       [73],\n",
              "       [ 8],\n",
              "       [66],\n",
              "       [68],\n",
              "       [59],\n",
              "       [ 1],\n",
              "       [68],\n",
              "       [69],\n",
              "       [74],\n",
              "       [ 1],\n",
              "       [63],\n",
              "       [63],\n",
              "       [70],\n",
              "       [74],\n",
              "       [55],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [55],\n",
              "       [76],\n",
              "       [62],\n",
              "       [ 1],\n",
              "       [73],\n",
              "       [59],\n",
              "       [55],\n",
              "       [74],\n",
              "       [ 1],\n",
              "       [55],\n",
              "       [59],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [72],\n",
              "       [68],\n",
              "       [58],\n",
              "       [ 1],\n",
              "       [62],\n",
              "       [ 1],\n",
              "       [74],\n",
              "       [63],\n",
              "       [73],\n",
              "       [70],\n",
              "       [59],\n",
              "       [72],\n",
              "       [55],\n",
              "       [74],\n",
              "       [59],\n",
              "       [ 1],\n",
              "       [73],\n",
              "       [69]])>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reformat to not be a lists of lists\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tNjdCfAdymp",
        "outputId": "7fbafe9d-5c2d-4ef8-db66-012e64f5e668"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([66,  0,  1,  1,  1, 79,  1, 77, 63, 71, 73, 69, 68,  1, 74, 62, 59,\n",
              "        1, 61, 72, 63, 73, 63, 57, 63, 55, 68,  1, 58, 59,  1, 73, 79,  1,\n",
              "       67, 69, 77, 59,  8,  0,  1,  0,  1,  1, 28, 68, 58, 72, 79,  1, 74,\n",
              "       69, 75, 74,  1, 58, 59, 73,  1, 57, 69, 69, 58, 59, 63, 55, 70, 74,\n",
              "       63, 69, 68, 73,  8, 66, 68, 59,  1, 68, 69, 74,  1, 63, 63, 70, 74,\n",
              "       55,  1,  1,  1, 55, 76, 62,  1, 73, 59, 55, 74,  1, 55, 59,  1,  1,\n",
              "       72, 68, 58,  1, 62,  1, 74, 63, 73, 70, 59, 72, 55, 74, 59,  1, 73,\n",
              "       69])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Given the input seq: \\n\")\n",
        "print(\"\".join(ind_to_char[input_example_batch[0]]))\n",
        "print('\\n')\n",
        "print(\"Next Char Predictions: \\n\")\n",
        "print(\"\".join(ind_to_char[sampled_indices ]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGP0tcAod2cG",
        "outputId": "c708b64e-5a29-45bc-83ad-d943ed5e6e87"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given the input seq: \n",
            "\n",
            "e:\n",
            "  My reason the physician to my love,  \n",
            "  Angry that his prescriptions are not kept\n",
            "  Hath left me, and I desperate n\n",
            "\n",
            "\n",
            "Next Char Predictions: \n",
            "\n",
            "l\n",
            "   y wiqson the grisician de sy mowe,\n",
            " \n",
            "  Cndry tout des coodeiaptions,lne not iipta   avh seat ae  rnd h tisperate so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('shakespeare_gen_L_1024.h5')"
      ],
      "metadata": {
        "id": "qvxzTXb5d4d0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(\n",
        "      vocab_size = vocab_size,\n",
        "      embed_dim=embed_dim,\n",
        "      rnn_neurons=rnn_neurons,\n",
        "      batch_size=1)\n",
        "\n",
        "model.load_weights('shakespeare_gen_L_1024.h5')\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "DzkTzHiWeAFA"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FJHM9MpeDSV",
        "outputId": "7a4fab00-5521-4a4a-ce5d-b61dd12705b7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (1, None, 64)             5248      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (1, None, 1024)           4460544   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, None, 82)             84050     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,549,842\n",
            "Trainable params: 4,549,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_seed,gen_size=100,temp=1.0):\n",
        "  '''\n",
        "  model: Trained Model to Generate Text\n",
        "  start_seed: Intial Seed text in string form\n",
        "  gen_size: Number of characters to generate\n",
        "\n",
        "  Basic idea behind this function is to take in some seed text, format it so\n",
        "  that it is in the correct shape for our network, then loop the sequence as\n",
        "  we keep adding our own predicted characters. Similar to our work in the RNN\n",
        "  time series problems.\n",
        "  '''\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = gen_size\n",
        "\n",
        "  # Vecotrizing starting seed text\n",
        "  input_eval = [char_to_ind[s] for s in start_seed]\n",
        "\n",
        "  # Expand to match batch format shape\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty list to hold resulting generated text\n",
        "  text_generated = []\n",
        "\n",
        "  # Temperature effects randomness in our resulting text\n",
        "  # The term is derived from entropy/thermodynamics.\n",
        "  # The temperature is used to effect probability of next characters.\n",
        "  # Higher probability == lesss surprising/ more expected\n",
        "  # Lower temperature == more surprising / less expected\n",
        " \n",
        "  temperature = temp\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "\n",
        "      # Generate Predictions\n",
        "      predictions = model(input_eval)\n",
        "\n",
        "      # Remove the batch shape dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # Use a cateogircal disitribution to select the next character\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # Pass the predicted charracter for the next input\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      # Transform back to character letter\n",
        "      text_generated.append(ind_to_char[predicted_id])\n",
        "\n",
        "  return (start_seed + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "kj4Vnv7peGDX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model,\"JULIET\",gen_size=1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7eVrmJeeHS1",
        "outputId": "978c360f-7d62-43cf-9ee9-0d47acd9f5a2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JULIETUDADP>PTEHPGEzXVTK<<TNNNHQP8DKQKvZ<UPAAIPGAQKZLAQH<QQURQVLADQVAWGP8QMAQH43HZ4J.HQK]DJOQGQK3TK&zJS<GQQ[]VQLA_H>QFDK82DKQ_QQYIQIRDDODQQKDDKQ\"<RQDQQHJQKDETNZ<<OQMLEW>WVQGQ>4Q_GDDHAIQWDCTQLQEIP9J_&KQPWD<DQZWAQP6W<X7<DO<<DQ\"QM>\"(5QVAQQJQP>8[ (5\"QLQHPQLEIUH8VQQAVjLUVEICICEOU(jQKAQDUqVIVAQUAQAQDQNDIzDP.HLIQUM\"QLJQDDH\"TVQQAIWQA|WVQVK\"1QKQDKVDIQODHQJI6N2QIjQPLQLXQHDH<QQ|Q<OHQKDQQDABLNHXDI8PGQ[NQOWV&7QKU_<IQID_Z!QVQJQLPDADQCQJEH&QZQBARQBAC\"_A<LLDHIjYQGDBODL(EGAX<NBDD(7QF_D\"VQQDQHLzG<Y(&NLQ7DQKDLEGQ\"DDQPQUMQXAL<TGQV<NY4<(Q_J[GHX7DLW0|GQK7D<GQU(DGDA[YQ&V(TQQL>GLQCECLAQCWOD_UJLTIEQUI<DWGCTD<DEG\"cVDQQEKX]D<\"zVQV\"<QR<DQQEDGCQGQLLQWLWKL\"VDIODQE\"4MSO8DZQD4QCIQ7VVPECTIVQUBR>XD(QVQX4]&BEQJOGQ\"&QWDQLEW4IQKQWFQKQUAP\n",
            "DACGEQLO7HLLQCJLTEWHA>B\n",
            "EQUYTHADPVDKBCUUMRDD>QZQRDQQOIPEGOQBRUDTSDDCTEQEPOW:6_LCLLLJBEQIQQLEXUPATQUJA(YQO<DQLQYDHg_TQ>GCLEIG_IQ<JTZLDJCAQTQIGQHDXDQLLDQQKPQKXQL8QLUTEIDGQKLQUMLQD<GCQOI>QCLLQ_BALDG<>8PG8<DDQTDCFQKXL(!G!DQOGLLQDDQQKLQQRQL<O]YQ\"SPEDXTDQXQQLEpQLPJ4QHDKVTV[IDQGKDTEXQOIQRQE7QTUPWEQRQK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model,\"But\",gen_size=1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igXvt66feIys",
        "outputId": "2de337f8-4c75-4095-ba9e-ac029e0b685f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "But!\n",
            "                 Enter Clroous wither trues in skelf,\n",
            "  And I'll be so by thee.\n",
            "DROMIO OF EPHESUS. I have way thou brokends,\n",
            "    Sherch, once, and my art and valiant of\n",
            "    things I will.\n",
            "  PAROLLES. I do deliver'd thy bewath ingent it humble!\n",
            "  ARVIRAGUS. Now I small to Antony. Most delieves Dia\n",
            "\n",
            "        Enter ORLANDO with his villainy on his preserver reputation\n",
            "    Could every day and ease thy best; they wand\n",
            "    My daughter's power,  \n",
            "    Abtorrends, for eightory\n",
            "    If you'd distire eyes when I am full from this mouth\n",
            "    Mare fair true kings\n",
            "    Or would he speaks way it off? Your blood,\n",
            "    All deports leave up a; 'tis all be we\n",
            "    Were his froild watch they hope himself awake, and leave him that your belly pleasing span\n",
            "                                                        Exeunt\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ACT IV SCENE 5.\n",
            "Rousillon. The COUNT'S palace\n",
            "\n",
            "Enter CYMBELINE and QUEEN\n",
            "  BRTTRILUS, on our stirring knew.\n",
            "  Hor. Indeed, let's do thee reserv'd. For myself,\n",
            "    I should be denied. I shall r\n"
          ]
        }
      ]
    }
  ]
}