{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9181a51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "728ef6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "path_to_file = 'shakespeare.txt'\n",
    "\n",
    "text = open(path_to_file, 'r').read()\n",
    "\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b379157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '}']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(vocab)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f5842c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " '(': 6,\n",
       " ')': 7,\n",
       " ',': 8,\n",
       " '-': 9,\n",
       " '.': 10,\n",
       " '0': 11,\n",
       " '1': 12,\n",
       " '2': 13,\n",
       " '3': 14,\n",
       " '4': 15,\n",
       " '5': 16,\n",
       " '6': 17,\n",
       " '7': 18,\n",
       " '8': 19,\n",
       " '9': 20,\n",
       " ':': 21,\n",
       " ';': 22,\n",
       " '<': 23,\n",
       " '>': 24,\n",
       " '?': 25,\n",
       " 'A': 26,\n",
       " 'B': 27,\n",
       " 'C': 28,\n",
       " 'D': 29,\n",
       " 'E': 30,\n",
       " 'F': 31,\n",
       " 'G': 32,\n",
       " 'H': 33,\n",
       " 'I': 34,\n",
       " 'J': 35,\n",
       " 'K': 36,\n",
       " 'L': 37,\n",
       " 'M': 38,\n",
       " 'N': 39,\n",
       " 'O': 40,\n",
       " 'P': 41,\n",
       " 'Q': 42,\n",
       " 'R': 43,\n",
       " 'S': 44,\n",
       " 'T': 45,\n",
       " 'U': 46,\n",
       " 'V': 47,\n",
       " 'W': 48,\n",
       " 'X': 49,\n",
       " 'Y': 50,\n",
       " 'Z': 51,\n",
       " '[': 52,\n",
       " ']': 53,\n",
       " '_': 54,\n",
       " '`': 55,\n",
       " 'a': 56,\n",
       " 'b': 57,\n",
       " 'c': 58,\n",
       " 'd': 59,\n",
       " 'e': 60,\n",
       " 'f': 61,\n",
       " 'g': 62,\n",
       " 'h': 63,\n",
       " 'i': 64,\n",
       " 'j': 65,\n",
       " 'k': 66,\n",
       " 'l': 67,\n",
       " 'm': 68,\n",
       " 'n': 69,\n",
       " 'o': 70,\n",
       " 'p': 71,\n",
       " 'q': 72,\n",
       " 'r': 73,\n",
       " 's': 74,\n",
       " 't': 75,\n",
       " 'u': 76,\n",
       " 'v': 77,\n",
       " 'w': 78,\n",
       " 'x': 79,\n",
       " 'y': 80,\n",
       " 'z': 81,\n",
       " '|': 82,\n",
       " '}': 83}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Step 2: Text Processing\n",
    "\n",
    "# ### Text Vectorization\n",
    "#\n",
    "# We know a neural network can't take in the raw string data, we need to assign numbers to each character. Let's create two dictionaries that can go from numeric index to character and character to numeric index.\n",
    "\n",
    "\n",
    "char_to_ind = {u: i for i, u in enumerate(vocab)}\n",
    "\n",
    "char_to_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a08d6caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1',\n",
       "       '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?',\n",
       "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
       "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
       "       '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n",
       "       'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n",
       "       'w', 'x', 'y', 'z', '|', '}'], dtype='<U1')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char = np.array(vocab)\n",
    "ind_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37766d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1, ..., 30, 39, 29])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = np.array([char_to_ind[c] for c in text])\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa61960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   \n",
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# We now have a mapping we can use to go back and forth from characters to numerics.\n",
    "\n",
    "sample = text[:20]\n",
    "\n",
    "print(sample)\n",
    "\n",
    "print(encoded_text[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6812c662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Step 3: Creating Batches\n",
    "#\n",
    "# Overall what we are trying to achieve is to have the model predict the next highest probability character given a historical sequence of characters. Its up to us (the user) to choose how long that historic sequence is. Too short a sequence and we don't have enough information (e.g. given the letter \"a\" , what is the next character?) , too long a sequence and training will take too long and most likely overfit to sequence characters that are irrelevant to characters farther out. While there is no correct sequence length choice, you should consider the text itself, how long normal phrases are in it, and a reasonable idea of what characters/words are relevant to each other.\n",
    "\n",
    "\n",
    "print(text[:500])\n",
    "\n",
    "line = \"From fairest creatures we desire increase\"\n",
    "\n",
    "len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27734bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_stanza = \"\"\"From fairest creatures we desire increase,\n",
    "  That thereby beauty's rose might never die,\n",
    "  But as the riper should by time decease,\"\"\"\n",
    "\n",
    "len(part_stanza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4a0bd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45005"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### Training Sequences\n",
    "#\n",
    "# The actual text data will be the text sequence shifted one character forward. For example:\n",
    "#\n",
    "# Sequence In: \"Hello my nam\"\n",
    "# Sequence Out: \"ello my name\"\n",
    "#\n",
    "#\n",
    "# We can use the `tf.data.Dataset.from_tensor_slices` function to convert a text vector into a stream of character indices.\n",
    "\n",
    "\n",
    "seq_len = 120\n",
    "\n",
    "total_num_seq = len(text) // (seq_len + 1)\n",
    "\n",
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c561512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "1\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "F\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "f\n",
      "a\n",
      "i\n",
      "r\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "c\n",
      "r\n",
      "e\n",
      "a\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "s\n",
      "i\n",
      "r\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "c\n",
      "r\n",
      "e\n",
      "a\n",
      "s\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "T\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "b\n",
      "y\n",
      " \n",
      "b\n",
      "e\n",
      "a\n",
      "u\n",
      "t\n",
      "y\n",
      "'\n",
      "s\n",
      " \n",
      "r\n",
      "o\n",
      "s\n",
      "e\n",
      " \n",
      "m\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "n\n",
      "e\n",
      "v\n",
      "e\n",
      "r\n",
      " \n",
      "d\n",
      "i\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "B\n",
      "u\n",
      "t\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "i\n",
      "p\n",
      "e\n",
      "r\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "t\n",
      "i\n",
      "m\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "c\n",
      "e\n",
      "a\n",
      "s\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "H\n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "e\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      " \n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      " \n",
      "m\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "b\n",
      "e\n",
      "a\n",
      "r\n",
      " \n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "m\n",
      "e\n",
      "m\n",
      "o\n",
      "r\n",
      "y\n",
      ":\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "B\n",
      "u\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "u\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "b\n",
      "r\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "e\n",
      "y\n",
      "e\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "F\n",
      "e\n",
      "e\n",
      "d\n",
      "'\n",
      "s\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "y\n",
      " \n",
      "l\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      "'\n",
      "s\n",
      " \n",
      "f\n",
      "l\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      "-\n",
      "s\n",
      "u\n",
      "b\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "t\n",
      "i\n",
      "a\n",
      "l\n",
      " \n",
      "f\n",
      "u\n",
      "e\n",
      "l\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "M\n",
      "a\n",
      "k\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      " \n",
      "f\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "a\n",
      "b\n",
      "u\n",
      "n\n",
      "d\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "l\n",
      "i\n",
      "e\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "T\n",
      "h\n",
      "y\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "y\n",
      " \n",
      "f\n",
      "o\n",
      "e\n",
      ",\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "y\n",
      " \n",
      "s\n",
      "w\n",
      "e\n",
      "e\n",
      "t\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      " \n",
      "t\n",
      "o\n",
      "o\n",
      " \n",
      "c\n",
      "r\n",
      "u\n",
      "e\n",
      "l\n",
      ":\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "T\n",
      "h\n",
      "o\n",
      "u\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "a\n",
      "r\n",
      "t\n",
      " \n",
      "n\n",
      "o\n",
      "w\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "l\n",
      "d\n",
      "'\n",
      "s\n",
      " \n",
      "f\n",
      "r\n",
      "e\n",
      "s\n",
      "h\n",
      " \n",
      "o\n",
      "r\n",
      "n\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "A\n",
      "n\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      "l\n",
      "y\n",
      " \n",
      "h\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "g\n",
      "a\n",
      "u\n",
      "d\n",
      "y\n",
      " \n",
      "s\n",
      "p\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "W\n",
      "i\n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "b\n",
      "u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 20:14:01.200213: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2022-05-03 20:14:01.200237: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: arch-rp\n",
      "2022-05-03 20:14:01.200241: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: arch-rp\n",
      "2022-05-03 20:14:01.200299: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.68.2\n",
      "2022-05-03 20:14:01.200312: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.60.2\n",
      "2022-05-03 20:14:01.200315: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 510.60.2 does not match DSO version 510.68.2 -- cannot find working devices in this configuration\n",
      "2022-05-03 20:14:01.200831: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Create Training Sequences\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
    "\n",
    "for i in char_dataset.take(500):\n",
    "    print(ind_to_char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53af382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The **batch** method converts these individual character calls into sequences we can feed in as a batch. We use seq_len+1 because of zero indexing. Here is what drop_remainder means:\n",
    "#\n",
    "# drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
    "#     whether the last batch should be dropped in the case it has fewer than\n",
    "#     `batch_size` elements; the default behavior is not to drop the smaller\n",
    "#     batch.\n",
    "#\n",
    "\n",
    "\n",
    "sequences = char_dataset.batch(seq_len + 1, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701c73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have our sequences, we will perform the following steps for each one to create our target text sequences:\n",
    "#\n",
    "# 1. Grab the input text sequence\n",
    "# 2. Assign the target text sequence as the input text sequence shifted by one step forward\n",
    "# 3. Group them together as a tuple\n",
    "\n",
    "\n",
    "def create_seq_targets(seq):\n",
    "    input_txt = seq[:-1]\n",
    "    target_txt = seq[1:]\n",
    "    return input_txt, target_txt\n",
    "\n",
    "\n",
    "dataset = sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99584d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
      "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
      "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
      " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
      " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But\n",
      "\n",
      "\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
      "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
      " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
      " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
      "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But \n"
     ]
    }
   ],
   "source": [
    "for input_txt, target_txt in dataset.take(1):\n",
    "    print(input_txt.numpy())\n",
    "    print(''.join(ind_to_char[input_txt.numpy()]))\n",
    "    print('\\n')\n",
    "    print(target_txt.numpy())\n",
    "    # There is an extra whitespace!\n",
    "    print(''.join(ind_to_char[target_txt.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94e700ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### Generating training batches\n",
    "#\n",
    "# Now that we have the actual sequences, we will create the batches, we want to shuffle these sequences into a random order, so the model doesn't overfit to any section of the text, but can instead generate characters given any seed text.\n",
    "\n",
    "\n",
    "# Batch size\n",
    "batch_size = 128\n",
    "\n",
    "# Buffer size to shuffle the dataset so it doesn't attempt to shuffle\n",
    "# the entire sequence in memory. Instead, it maintains a buffer in which it shuffles elements\n",
    "buffer_size = 10000\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9036407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Step 4: Creating the Model\n",
    "\n",
    "# This is where YOU will create the model. it needs to start with an embedding layer.\n",
    "#\n",
    "# The embedding layer will serve as the input layer, which essentially creates a lookup table that maps the numbers indices of each character to a vector with \"embedding dim\" number of dimensions. As you can imagine, the larger this embedding size, the more complex the training. This is similar to the idea behind word2vec, where words are mapped to some n-dimensional space. Embedding before feeding straight into the LSTM or GRU usually leads to more realisitic results.\n",
    "\n",
    "\n",
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension. Your choice.\n",
    "embed_dim = 64\n",
    "\n",
    "# Number of RNN units. Your choice. YOU MUST EXPERIMENT WITH THIS NUMBER.\n",
    "rnn_neurons = 256\n",
    "\n",
    "# Now let's create a function that easily adapts to different variables as shown above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2a23aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f805da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Setting up Loss Function\n",
    "#\n",
    "# For our loss we will use sparse categorical crossentropy, which we can import from Keras. We will also set this as logits=True\n",
    "\n",
    "\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "\n",
    "# The reason we need to redefine this is to make sure we are using one hot encoding (from_logits=True)\n",
    "def sparse_cat_loss(y_true, y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e9e2b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
    "    # define your model here...\n",
    "    # don't forget you need an embeddings layer at the beginning\n",
    "    # and a dense layer the size of the vocabulary at the end to generate distributions\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embed_dim,batch_input_shape=[batch_size, None]))\n",
    "    model.add(LSTM(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
    "    # Final Dense Layer to Predict\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.compile(optimizer='adam', loss=sparse_cat_loss, metrics=['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc1e2db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "351/351 [==============================] - 60s 167ms/step - loss: 2.6284\n",
      "Epoch 2/30\n",
      "351/351 [==============================] - 80s 225ms/step - loss: 1.9725\n",
      "Epoch 3/30\n",
      "351/351 [==============================] - 61s 172ms/step - loss: 1.7858\n",
      "Epoch 4/30\n",
      "351/351 [==============================] - 47s 132ms/step - loss: 1.6710\n",
      "Epoch 5/30\n",
      "351/351 [==============================] - 47s 132ms/step - loss: 1.5933\n",
      "Epoch 6/30\n",
      "351/351 [==============================] - 50s 141ms/step - loss: 1.5377\n",
      "Epoch 7/30\n",
      "351/351 [==============================] - 96s 271ms/step - loss: 1.4945\n",
      "Epoch 8/30\n",
      "351/351 [==============================] - 98s 278ms/step - loss: 1.4609\n",
      "Epoch 9/30\n",
      "351/351 [==============================] - 96s 272ms/step - loss: 1.4341\n",
      "Epoch 10/30\n",
      "351/351 [==============================] - 97s 274ms/step - loss: 1.4118\n",
      "Epoch 11/30\n",
      "351/351 [==============================] - 98s 278ms/step - loss: 1.3935\n",
      "Epoch 12/30\n",
      "351/351 [==============================] - 93s 264ms/step - loss: 1.3777\n",
      "Epoch 13/30\n",
      "351/351 [==============================] - 101s 286ms/step - loss: 1.3643\n",
      "Epoch 14/30\n",
      "351/351 [==============================] - 92s 261ms/step - loss: 1.3526\n",
      "Epoch 15/30\n",
      "351/351 [==============================] - 53s 148ms/step - loss: 1.3426\n",
      "Epoch 16/30\n",
      "351/351 [==============================] - 48s 134ms/step - loss: 1.3329\n",
      "Epoch 17/30\n",
      "351/351 [==============================] - 49s 137ms/step - loss: 1.3252\n",
      "Epoch 18/30\n",
      "351/351 [==============================] - 52s 146ms/step - loss: 1.3180\n",
      "Epoch 19/30\n",
      "351/351 [==============================] - 75s 210ms/step - loss: 1.3106\n",
      "Epoch 20/30\n",
      "351/351 [==============================] - 68s 193ms/step - loss: 1.3048\n",
      "Epoch 21/30\n",
      "351/351 [==============================] - 57s 160ms/step - loss: 1.2995\n",
      "Epoch 22/30\n",
      "351/351 [==============================] - 51s 145ms/step - loss: 1.2943\n",
      "Epoch 23/30\n",
      "351/351 [==============================] - 68s 193ms/step - loss: 1.2896\n",
      "Epoch 24/30\n",
      "351/351 [==============================] - 74s 209ms/step - loss: 1.2854\n",
      "Epoch 25/30\n",
      "351/351 [==============================] - 72s 204ms/step - loss: 1.2809\n",
      "Epoch 26/30\n",
      "351/351 [==============================] - 70s 198ms/step - loss: 1.2775\n",
      "Epoch 27/30\n",
      "351/351 [==============================] - 72s 202ms/step - loss: 1.2738\n",
      "Epoch 28/30\n",
      "351/351 [==============================] - 71s 200ms/step - loss: 1.2705\n",
      "Epoch 29/30\n",
      "351/351 [==============================] - 72s 205ms/step - loss: 1.2674\n",
      "Epoch 30/30\n",
      "351/351 [==============================] - 72s 204ms/step - loss: 1.2646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1691f31160>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the model\n",
    "model = create_model(\n",
    "  vocab_size = vocab_size,\n",
    "  embed_dim=embed_dim,\n",
    "  rnn_neurons=rnn_neurons,\n",
    "  batch_size=batch_size)\n",
    "\n",
    "\n",
    "#Train the model\n",
    "epochs = 30\n",
    "model.fit(dataset,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8968957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.628352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.972550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.785797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.670965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.593349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss\n",
       "0  2.628352\n",
       "1  1.972550\n",
       "2  1.785797\n",
       "3  1.670965\n",
       "4  1.593349"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "losses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "686833bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhUElEQVR4nO3deZRcdZ338fe3q6u7eu+ku9NLtk4wIIGQhU4AgaDjKIqOTMRlUNlGjD4P4+CjZ46POo7L6OjIuBxHIU8GEHBQYEzEdUAc0YCsnRDI0ggkkqSTTtLppPe9+/v8UdVNE3rv6lTXrc/rnDp1+95fVX3vuSefuvnV7/6uuTsiIhIMaYkuQERE4kehLiISIAp1EZEAUaiLiASIQl1EJEDSE/XBxcXFXllZmaiPFxFJSlu3bj3m7iUjbU9YqFdWVlJdXZ2ojxcRSUpmtm+07ep+EREJEIW6iEiAKNRFRAIkYX3qIiLx0NPTQ21tLZ2dnYkuJa4ikQjz5s0jHA5P6HUKdRFJarW1teTl5VFZWYmZJbqcuHB3GhoaqK2tZdGiRRN6rbpfRCSpdXZ2UlRUFJhABzAzioqKJvW/D4W6iCS9IAX6gMnuU9KF+vOHm/nGA8/T1N6T6FJERGacpAv1fQ3t3Pz7Pew/3p7oUkREAMjNzU10CYPGDHUzm29mD5vZbjPbZWY3jtDujWa2PdbmD/EvNaqiIAuAQ00d0/URIiJJazxn6r3Ap9x9KXA+cIOZLR3awMwKgZuBd7n7WcB7413ogLKCCACHm4I1fElEkp+78w//8A+cffbZLFu2jHvvvReAuro61q5dy4oVKzj77LN55JFH6Ovr49prrx1s++1vfzsuNYw5pNHd64C62HKLmdUAc4HdQ5p9ANjs7vtj7Y7GpbphFOVkEA4ZdQp1ETnJl36xi92HmuP6nksr8vnCX501rrabN29m+/btPPvssxw7dozVq1ezdu1afvSjH3HppZfyuc99jr6+Ptrb29m+fTsHDx5k586dADQ2Nsal3gn1qZtZJbASePKkTacDs8zs92a21cyuHuH1682s2syq6+vrJ1dwmlGaH+Gwul9EZIZ59NFHufLKKwmFQpSWlnLJJZfw9NNPs3r1an7wgx/wxS9+kR07dpCXl8fixYvZu3cvH//4x3nggQfIz8+PSw3jvvjIzHKBTcAn3P3kr8J04FzgzUAW8LiZPeHuLwxt5O4bgY0AVVVVk77jdUVBFod0pi4iJxnvGfWptnbtWrZs2cKvfvUrrr32Wj75yU9y9dVX8+yzz/Lggw+yYcMG7rvvPm6//fYpf9a4ztTNLEw00O92983DNKkFHnT3Nnc/BmwBlk+5uhGUFUTUpy4iM87FF1/MvffeS19fH/X19WzZsoU1a9awb98+SktL+chHPsL111/Ptm3bOHbsGP39/VxxxRV85StfYdu2bXGpYcwzdYuOgL8NqHH3b43Q7GfA98wsHcgAzgPi0+s/jPKCCA/s7MTdA3nRgYgkp3Xr1vH444+zfPlyzIxvfOMblJWVceedd3LTTTcRDofJzc3lrrvu4uDBg1x33XX09/cD8LWvfS0uNYyn++VC4Cpgh5ltj637LLAAwN03uHuNmT0APAf0A7e6+864VDiMsoII3X39HG/rpig3c7o+RkRkXFpbW4HoVaA33XQTN91006u2X3PNNVxzzTWveV28zs6HGs/ol0eBMU+H3f0m4Kax2sVDeWysel1Tp0JdRGSIpLuiFKLdL4CGNYqInCSpQ13DGkUEohf9BM1k9ykpQ704N5P0NF2AJCLRm0k0NDQEKtgH5lOPRCITfm1S3iRj4AIkhbqIzJs3j9raWiZ7QeNMNXDno4lKylCHaBdMnbpfRFJeOBye8N2Bgiwpu19AFyCJiAwnaUO9ojCLuqbOQPWjiYhMVdKGell+hK7efk7oDkgiIoOSNtRfGauufnURkQFJG+q6WYaIyGslbahXFA7c1k6hLiIyIGlDvTg3k1Ca6apSEZEhkjbUQ2lGaV6mLkASERkiaUMdNFZdRORkSR3q5bGx6iIiEpXcoZ4fnSpAFyCJiEQldaiXFUTo7OmnqUMXIImIQJKH+sCwRnXBiIhEJXWol+mqUhGRV0nqUNdt7UREXm3MUDez+Wb2sJntNrNdZnbjKG1Xm1mvmb0nvmUOryQ3kzTTVAEiIgPGc5OMXuBT7r7NzPKArWb2kLvvHtrIzELAvwK/mYY6h5UeStMdkEREhhjzTN3d69x9W2y5BagB5g7T9OPAJuBoXCscQ5nugCQiMmhCfepmVgmsBJ48af1cYB1wyxivX29m1WZWHa/7CUZva6czdRERmECom1ku0TPxT7h780mbvwN82t37R3sPd9/o7lXuXlVSUjLhYodTlp/FYd0BSUQEGOeNp80sTDTQ73b3zcM0qQLuMTOAYuAyM+t19/vjVehIKgojtHf30dzRS0F2eLo/TkRkRhsz1C2a1LcBNe7+reHauPuiIe3vAH55KgIdhoxVb+5QqItIyhvPmfqFwFXADjPbHlv3WWABgLtvmJ7SxmfoWPXXl+UnshQRkYQbM9Td/VHAxvuG7n7tVAqaqLKC6FQBGqsuIpLkV5QCzMmLXoBU16hhjSIiSR/q4VAaJboDkogIEIBQh2gXzOFmhbqISCBCvUIXIImIAAEJ9bKCCHWNugOSiEggQr28IEJbdx8tXb2JLkVEJKECEeoa1igiEhWIUK/QzTJERICAhPrgVAEaqy4iKS4QoT4nL4KZztRFRAIR6hnpaRTnZqpPXURSXiBCHWJj1XUBkoikuMCE+sBYdRGRVBaYUC8vyFL3i4ikvMCEellBhJauXlo6exJdiohIwgQm1AdulqGzdRFJZQEK9ehVpRrWKCKpLEChrjN1EZHAhHppvqYKEBEJTKgPXIBU16RhjSKSusYMdTObb2YPm9luM9tlZjcO0+aDZvacme0ws8fMbPn0lDu6ct0sQ0RSXPo42vQCn3L3bWaWB2w1s4fcffeQNn8GLnH3E2b2dmAjcN401DuqsoII+xvaT/XHiojMGGOeqbt7nbtviy23ADXA3JPaPObuJ2J/PgHMi3eh4xG9rZ26X0QkdU2oT93MKoGVwJOjNPsw8N8jvH69mVWbWXV9ff1EPnpcygqyaO7spU13QBKRFDXuUDezXGAT8Al3bx6hzZuIhvqnh9vu7hvdvcrdq0pKSiZT76jKdbMMEUlx4wp1MwsTDfS73X3zCG3OAW4FLnf3hviVOH5lGqsuIiluPKNfDLgNqHH3b43QZgGwGbjK3V+Ib4njVzF4Van61UUkNY1n9MuFwFXADjPbHlv3WWABgLtvAP4JKAJujn4H0OvuVXGvdgxz8jMBdb+ISOoaM9Td/VHAxmhzPXB9vIqarEg4RFFOhkJdRFJWYK4oHVBWEOGwul9EJEUFLtTLC7J0pi4iKSuAoa6pAkQkdQUu1MsKIjR19NDerQuQRCT1BC7UKwo1Vl1EUlfgQr0sX3dAEpHUFbhQ11QBIpLKAhfqr0wVoGGNIpJ6AhfqkXCI2boASURSVOBCHaAsX8MaRSQ1BTLUNVZdRFJVIENdUwWISKoKZKhXFGZxor2Hzp6+RJciInJKBTLUy/I1rFFEUlMgQ/2VserqghGR1BLIUNdt7UQkVQUy1MsLNFWAiKSmQIZ6VkaIwuywul9EJOUEMtQh+mOpul9EJNUENtQrCnUHJBFJPWOGupnNN7OHzWy3me0ysxuHaWNm9l0ze8nMnjOzVdNT7vhFL0BSqItIahnPmXov8Cl3XwqcD9xgZktPavN2YEnssR64Ja5VTkJ5foSGtm5dgCQiKWXMUHf3OnffFltuAWqAuSc1uxy4y6OeAArNrDzu1U7AwLDGI806WxeR1DGhPnUzqwRWAk+etGkucGDI37W8Nvgxs/VmVm1m1fX19RMsdWIqCjWsUURSz7hD3cxygU3AJ9y9eTIf5u4b3b3K3atKSkom8xbjVqarSkUkBY0r1M0sTDTQ73b3zcM0OQjMH/L3vNi6hNH8LyKSisYz+sWA24Aad//WCM1+DlwdGwVzPtDk7nVxrHPCcjLTyY+kawSMiKSU9HG0uRC4CthhZttj6z4LLABw9w3Ar4HLgJeAduC6uFc6CYtLcnlmf2OiyxAROWXGDHV3fxSwMdo4cEO8ioqXy1dU8KVf7Gb3oWaWVuQnuhwRkWkX2CtKAdatnEtGehr3VR8Yu7GISAAEOtQLszO49KwyfvrMQV2EJCIpIdChDvD+qvk0dfTw4K7DiS5FRGTaBT7U33BaEfNmZakLRkRSQuBDPS3NeF/VfP74UgMHjrcnuhwRkWkV+FAHeM+58zCD/9LZuogEXEqEekVhFmuXlPBfW2vp6/dElyMiMm1SItQB3r96PnVNnWx5cXonEhMRSaSUCfW/PLOU2TkZ3Pe0umBEJLhSJtQz0tN498q5/LbmCMdauxJdjojItEiZUIdoF0xPn/PTbQmdQFJEZNqkVKgvKc1j1YJC7q0+QHS6GhGRYEmpUIfo2fpLR1vZptkbRSSAUi7U33FOBdkZIf1gKiKBlHKhnpuZzjvPKecXzx2itas30eWIiMRVyoU6wPtXL6C9u49fPXco0aWIiMRVSob6qgWFvG5OLveqC0ZEAiYlQ93MeH/VfLbtb+TFIy2JLkdEJG5SMtQB1q2aS3qa6WxdRAIlZUO9ODeTtywtZfMzB+nu7U90OSIicTFmqJvZ7WZ21Mx2jrC9wMx+YWbPmtkuM7su/mVOj/etns/xtm7+p+ZIoksREYmL8Zyp3wG8bZTtNwC73X058Ebgm2aWMfXSpt/aJSWUF0S4V/Osi0hAjBnq7r4FOD5aEyDPzAzIjbVNigHgoTTjPefO4w8v1HOosSPR5YiITFk8+tS/B5wJHAJ2ADe6+7Cd1Ga23syqzay6vn5mzGv+vqr5uMNPttYmuhQRkSmLR6hfCmwHKoAVwPfMLH+4hu6+0d2r3L2qpKQkDh89dfNnZ3Ph64q4r/oA/borkogkuXiE+nXAZo96Cfgz8Po4vO8pc+WaBdSe6OAn23S2LiLJLR6hvh94M4CZlQJnAHvj8L6nzGVnl1O1cBb/8usaGnQDDRFJYuMZ0vhj4HHgDDOrNbMPm9nHzOxjsSb/DLzBzHYA/wN82t2PTV/J8ZeWZnzt3cto6+rlK7+qSXQ5IiKTlj5WA3e/cozth4C3xq2iBFlSmsf/uuQ0vvu7l3j3qrlcvGRm9PmLiExEyl5ROpz//abXsbg4h8/9dCcd3X2JLkdEZMIU6kNEwiG+um4Z+4+3893fvZjockREJkyhfpILTivivefOY+OWvdTUNSe6HBGRCVGoD+Ozl51JYVaYz2zeQZ/GrotIElGoD2NWTgaff+dSth9o5D+f2JfockRExk2hPoLLV1Rw8ZJibnrwT9Q1aV4YEUkOCvURmBlf/etl9Pb384Wf7Up0OSIi46JQH8WComxufPPp/Gb3ER7cdTjR5YiIjEmhPobrL17E68vy+MLPdtHS2ZPockRERqVQH0M4lMbXrziHIy2d/NuDf0p0OSIio1Koj8OK+YVcc0Eldz2xj2f2n0h0OSIiI1Koj9On3no6pXkRPrN5Bz19ulG1iMxMCvVxyouE+fLlZ/H84Ra+//BLiS5HRGRYCvUJeOtZZaxbOZfv/PZF7n16f6LLERF5jTGn3pVX+9crzqGhrZvPbN5BXiTMZcvKE12SiMggnalPUEZ6Ghs+tIpVC2Zx4z3PsOWFmXEDbRERUKhPSnZGOrddu5rXzcnjoz/cytZ9xxNdkogIoFCftIKsMHf97RrKCiJc94OnNU2viMwICvUpKMnL5IcfXkNOZjpX3fYUfz7WluiSRCTFKdSnaN6sbH744fPod+dDtz6pGR1FJKHGDHUzu93MjprZzlHavNHMtpvZLjP7Q3xLnPleNyeXO69bQ1NHD1fd9hTH27oTXZKIpKjxnKnfAbxtpI1mVgjcDLzL3c8C3huXypLMsnkF3HpNFQeOt3PN7U9p8i8RSYgxQ93dtwCjDe/4ALDZ3ffH2h+NU21J5/zFRdz8wVXU1DVz/Z3VdPb0JbokEUkx8ehTPx2YZWa/N7OtZnb1SA3NbL2ZVZtZdX19MMd3v/nMUr75vuU89fJxbrh7m4JdRE6peIR6OnAu8A7gUuDzZnb6cA3dfaO7V7l7VUlJSRw+ema6fMVcvnz52fzP80e54pbH2N/QnuiSRCRFxCPUa4EH3b3N3Y8BW4DlcXjfpHbV+Qu5LdbH/o5/f4SHdh9JdEkikgLiEeo/Ay4ys3QzywbOA2ri8L5J781nlvKrv7+YhUXZfOSuar7+38/Tq2l7RWQajWdI44+Bx4EzzKzWzD5sZh8zs48BuHsN8ADwHPAUcKu7jzj8MdXMn53NTz72Bq5cs4ANf9jDh257kqMtnYkuS0QCytw9IR9cVVXl1dXVCfnsRNm0tZbP3b+D/EiY731gFWsWzU50SSKSZMxsq7tXjbRdV5SeQlecO4/7b7iQnMx0rvyPJ9i4ZQ+J+lIVkWBSqJ9iry/L5+d/dyFvXVrKv/z6eT76w60060IlEYkThXoC5EXC3PzBVfzjO87kd88f5a/+/VF21DYluiwRCQCFeoKYGddfvJh71p9PZ08fl3//UT5//06a2nXWLiKTp1BPsKrK2fzm/1zC1RdUcveT+3jTN3/PvU/vp79ffe0iMnEK9RmgICvMF991Fr/8+MWcVpLDpzftYN0tj/FcbWOiSxORJKNQn0GWVuRz30cv4NvvX86hxg4u//4f+czmHZrKV0TGTaE+w5gZ61bO43efuoS/vXAR91Uf4C+++Xv+84l99KlLRkTGoFCfofIiYT7/zqX8+u8v5ozSPP7x/p1c/v1H2brvRKJLE5EZTKE+w51Rlsc968/nu1eupL6liytueYyrb3+Kx/Yc04VLIvIamiYgibR29XLHH//MHY+9zLHWbpbPK+Cjl5zGpWeVEUqzRJcnIqfAWNMEKNSTUGdPH5u21bJxy172NbRTWZTNR9Yu5opV84iEQ4kuT0SmkUI9wPr6nQd3HWbDH/bwXG0TxbmZXHdhJR86fyEFWeFElyci00ChngLcncf3NrDhD3vZ8kI9ORkhPnDeAq55QyXzZmUnujwRiSOFeorZdaiJjVv28svn6ujrd85fPJsrVs3jsmXl5GSmJ7o8EZkihXqKOtjYwaattWzeVsvLDe1khUO8/ewyrjh3HhcsLiJNP6yKJCWFeopzd7buO8GmbbX88tk6Wrp6qSiIsG7VXK5YNY/FJbmJLlFEJkChLoM6e/r4ze4jbNpayyMv1tPvsHJBIe9eNY9Ll5YyJz+S6BJFZAwKdRnWkeZOfrb9IJu2HuRPR1oAWD6/kLcuLeUtS0tZMicXM3XRiMw0CnUZlbvzwpFWHtp9mIdqjvLsgUYAFhZl85dnRgO+auEs0kO6+FhkJphyqJvZ7cA7gaPufvYo7VYDjwN/4+4/GaswhfrMdKS5k9/WHOG3u4/wxz0NdPf2U5gd5i/OmMNblpZy0ZJi8iIaAy+SKPEI9bVAK3DXSKFuZiHgIaATuF2hHgxtXb1seaGeh2qO8Lvnj9LY3kOawbK5BZx/WhHnLy5ideVscjVUUuSUiUv3i5lVAr8cJdQ/AfQAq2PtFOoB09vXz9Z9J/jjngae2NPAMwdO0NPnhNKMZXMLuOC0Ii5YXERV5SyyMxTyItNlrFCf8r8+M5sLrAPeRDTUR2u7HlgPsGDBgql+tJxC6aE0zltcxHmLi+At0NHdx9Z9J3hibwOP723gP7bs5Zbf7yE9zVg+v5DzFs3m3IWzWDG/kKLczESXL5Iy4nFK9R3g0+7eP9ZoCXffCGyE6Jl6HD5bEiQrI8RFS4q5aEkxEO2q2brvBI/vbeDxPQ38vy17B2/qsbAom5XzC1kxv5CVC2ZxZnk+Gen64VVkOsQj1KuAe2KBXgxcZma97n5/HN5bkkROZjprTy9h7eklQPRMfsfBJp7Zf4Jn9jfy2J4G7t9+CICM9DSWzS1gZSzkl80tYP7sLA2hFImDKYe6uy8aWDazO4j2qd8/1feV5JaVEWLNotmsWTQbiA6drGvq5Jn9jdGgP9DIXU/s49ZH/wxAXmY6ry/P48zyfJaW53NmeT5nlOVpKmGRCRoz1M3sx8AbgWIzqwW+AIQB3H3DtFYngWFmVBRmUVGYxTvOKQegu7efmrpmdh1qpqYu+ti0tZa7uvsASDNYXJLLmeX5nBkL/CVzcqkoyNLcNSIj0MVHMqP09zsHTrRTU9fM7roWdscC/2Bjx2Cb7IwQp5Xk8ro5rzyWzMllwexsXSQlgTfto19E4iktzVhYlMPCohzednb54Pqmjh7+dLiFl4628uLR6PMTexv46TMHB9tkhNKoLM5myZw8FhXnsLAom4VFOVQWZVOSl6k+e0kJCnVJCgVZ4Vf10Q9o6exhT33bYNjvOdrKzkNNPLDr8ODoG4CscCgW8tmxL41sFs6OPpcXRHSGL4GhUJeklhcJsyI2XHKonr5+Dp7o4OWGNvYfb+flY+3sP97Gnvo2Hv5TPd29/YNt09OMubOyWDA7+1WP+bOzWVCUTb6mRZAkolCXQAqH0qgszqGyOOc12/r7ncPNnexraGdfQxsHTrSz/3gH+xva+PWOOk6097yqfWF2mIWzs6kozKI0P0JZQYTyggil+a88a5SOzBQKdUk5aWmvjMS54LSi12xv7uzhwPF2DhxvZ//xdvY1RJ9fPNrKIy8eo7Wr9zWvKcwOUxYL/LL8CHPyI8zJy2ROXial+RHm5GdSnJtJWN08Ms0U6iInyY+EOauigLMqCobd3trVy+GmzuijuZPDTR2x5y4ON3ew82AzDW1dnDywzAyKcjIoyYvEwn4g8COUxsK/ND9CcW6G+vhl0hTqIhOUm5k+OJRyJL19/TS0dXOkuZOjzV0cbemKLrd0cTT2XFPXzLHWLvqHCf/i3Fjo571y1l+Um8HsnJMe2foCkFdTqItMg/RQ2uCZ92j6+p2G1i6ONEdD/0hLJ0eao8F/pLmTuqZOnq1t5Fhr94jvUZAVfk3QF2aHKczOYFZ2eMjywPowmen6DSCoFOoiCRRKs+iZeH6EZQzf3QPRM/8T7T0cb+se8uiiIbbc0NbNibZuDhxv57naRk6097xqhM/JsjNCFGZFw74wO8ys7AwKssPRL4GsgeXYl0BWmILsMPmRsH4QTgIKdZEkkB5KoyQvk5K88U1j7O509PRxor2HxvZuGtt7aGzv4UR79+DfJ9p7aOro5kR7D88fbqapI7qu7+T+oCEy09PIzwpTEHvkR9Kjz4N/h8mLpJMXe86NpJM/5O+scEgXgU0zhbpIAJkZ2RnpZGekM7cwa9yvc3dau3oHvwQaY6Hf1NFDc+zR1NFDc2f0+VhrN3vq22jujG4b5fsAiP7PJDczfTD48yPp5A/5MsjPGrouPbY+THZmiNzMdLIzQmRnpBPS3D8jUqiLyCAzi51Vh5k/e+z2Q/X3O23dvbR0Djx6aOkastzZS+uQ5ebO3sHhoy2x5ZbO1w4XHU4knEZORjrZmaHoc0aInMx0cjLSyYl9aeRkRtflZUbXnbyckxkiOxx9jyANNVWoi0hcpKW98oUwWX390f8pNMf+N9DSGV3u6OmjrauP9u7eV567e2nv6os+d/fR2tXLkeZO2rr6aOnsoa27b9SupKHCoYH/2YQG/zcwdDkrtpyVEfsiGFgeXB9bFw4RCUe3ZYWjj8z0tFM6q6hCXURmjFCaDfbXT5W709XbT0tnL21dvbQOPDp7B78I2rv7aO/qpb0n9jywLrb9WGs37d3tdHT3Rdt09436A/RIMtPTXhX0HzhvAddfvHjK+zgchbqIBJKZEYmdOY/3B+bx6O3rp6OnLxr0sUdHT/RLoLMnuq2zuy/aJtauc8hyR08fxdN4316FuojIBKSH0sgLpU2pm2k6BefXARERUaiLiASJQl1EJEAU6iIiATJmqJvZ7WZ21Mx2jrD9g2b2nJntMLPHzGx5/MsUEZHxGM+Z+h3A20bZ/mfgEndfBvwzsDEOdYmIyCSMOaTR3beYWeUo2x8b8ucTwLw41CUiIpMQ7z71DwP/PdJGM1tvZtVmVl1fXx/njxYRkbhdfGRmbyIa6heN1MbdNxLrnjGzejPbN8mPKwaOTfK1M1XQ9ilo+wPB26eg7Q8Eb5+G25+Fo70gLqFuZucAtwJvd/eG8bzG3Uum8HnV7l412dfPREHbp6DtDwRvn4K2PxC8fZrM/ky5+8XMFgCbgavc/YWpvp+IiEzemGfqZvZj4I1AsZnVAl8AwgDuvgH4J6AIuDl2R5PeIH1Tiogkk/GMfrlyjO3XA9fHraLxCeKwyaDtU9D2B4K3T0HbHwjePk14f8x9fJPIi4jIzKdpAkREAkShLiISIEkX6mb2NjP7k5m9ZGb/N9H1xIOZvRybO2e7mVUnup6JGm5+IDObbWYPmdmLsedZiaxxokbYpy+a2cHYcdpuZpclssaJMLP5Zvawme02s11mdmNsfVIep1H2J5mPUcTMnjKzZ2P79KXY+kVm9mQs8+41s4xR3yeZ+tTNLAS8ALwFqAWeBq50990JLWyKzOxloMrdk/KiCTNbC7QCd7n72bF13wCOu/vXY1++s9z904mscyJG2KcvAq3u/m+JrG0yzKwcKHf3bWaWB2wF/hq4liQ8TqPsz/tI3mNkQI67t5pZGHgUuBH4JLDZ3e8xsw3As+5+y0jvk2xn6muAl9x9r7t3A/cAlye4ppTn7luA4yetvhy4M7Z8J9F/cEljhH1KWu5e5+7bYsstQA0wlyQ9TqPsT9LyqNbYn+HYw4G/AH4SWz/mMUq2UJ8LHBjydy1JfiBjHPiNmW01s/WJLiZOSt29LrZ8GChNZDFx9HexqaZvT5auipPFJuhbCTxJAI7TSfsDSXyMzCxkZtuBo8BDwB6g0d17Y03GzLxkC/WgusjdVwFvB26I/dc/MDzax5c8/XwjuwU4DVgB1AHfTGg1k2BmucAm4BPu3jx0WzIep2H2J6mPkbv3ufsKorPdrgFeP9H3SLZQPwjMH/L3vNi6pObuB2PPR4GfEj2Yye5IrN9zoP/zaILrmTJ3PxL7R9cP/AdJdpxi/bSbgLvdfXNsddIep+H2J9mP0QB3bwQeBi4ACs1s4ELRMTMv2UL9aWBJ7NfgDOBvgJ8nuKYpMbOc2A89mFkO8FZg2LtMJZmfA9fElq8BfpbAWuJiIPxi1pFExyn2I9xtQI27f2vIpqQ8TiPtT5IfoxIzK4wtZxEdEFJDNNzfE2s25jFKqtEvALEhSt8BQsDt7v7VxFY0NWa2mOjZOUSnbfhRsu3T0PmBgCNE5we6H7gPWADsA97n7knzw+MI+/RGov+td+Bl4KND+qNnNDO7CHgE2AH0x1Z/lmg/dNIdp1H250qS9xidQ/SH0BDRE+773P3LsYy4B5gNPAN8yN27RnyfZAt1EREZWbJ1v4iIyCgU6iIiAaJQFxEJEIW6iEiAKNRFRAJEoS4iEiAKdRGRAPn/K4N/KyoglSwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses[['loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3eb650fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'metric')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = losses.plot(lw=2, colormap='jet', marker='.', markersize=10, title='Loss and Accuracy trend during training')\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34d9d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('asdfds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c885f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('shakespeare_gen_L_256.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c557284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(\n",
    "      vocab_size = vocab_size,\n",
    "      embed_dim=embed_dim,\n",
    "      rnn_neurons=rnn_neurons,\n",
    "      batch_size=1)\n",
    "\n",
    "model.load_weights('shakespeare_gen_L_256.h5')\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f58f6717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (1, None, 64)             5376      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (1, None, 256)            328704    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (1, None, 84)             21588     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355,668\n",
      "Trainable params: 355,668\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ceaf0440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_seed,gen_size=100,temp=1.0):\n",
    "  '''\n",
    "  model: Trained Model to Generate Text\n",
    "  start_seed: Intial Seed text in string form\n",
    "  gen_size: Number of characters to generate\n",
    "\n",
    "  Basic idea behind this function is to take in some seed text, format it so\n",
    "  that it is in the correct shape for our network, then loop the sequence as\n",
    "  we keep adding our own predicted characters. Similar to our work in the RNN\n",
    "  time series problems.\n",
    "  '''\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = gen_size\n",
    "\n",
    "  # Vecotrizing starting seed text\n",
    "  input_eval = [char_to_ind[s] for s in start_seed]\n",
    "\n",
    "  # Expand to match batch format shape\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty list to hold resulting generated text\n",
    "  text_generated = []\n",
    "\n",
    "  # Temperature effects randomness in our resulting text\n",
    "  # The term is derived from entropy/thermodynamics.\n",
    "  # The temperature is used to effect probability of next characters.\n",
    "  # Higher probability == lesss surprising/ more expected\n",
    "  # Lower temperature == more surprising / less expected\n",
    " \n",
    "  temperature = temp\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "\n",
    "  for i in range(num_generate):\n",
    "\n",
    "      # Generate Predictions\n",
    "      predictions = model(input_eval)\n",
    "\n",
    "      # Remove the batch shape dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # Use a cateogircal disitribution to select the next character\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # Pass the predicted charracter for the next input\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      # Transform back to character letter\n",
    "      text_generated.append(ind_to_char[predicted_id])\n",
    "\n",
    "  return (start_seed + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9ea3bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JULIETIGQOKMQ2Q8KzQ}-szXX\"|PGQOQOQ(D]EMTXKQ8[SQxXQO[SPQOTXQVQKQ2QVTOAXK<[QRQO0QVQ7QQ[9Q[wQOHGCQOQwKVQ[FQr[OQ&V0JVTQO`Q[MQZQxwQORQ&YKKXZXQ[&AQ1QS(4Q5WIPQQO7QgQQ[x_\"8QXVQ\"&AQQOQOKKQ|>3Q(9KQ_4QxQOVQQOQ6Q8Q`QrXQ2Q&`Ggd[`QOQcg8Q0Q5Q&XMVQ&`QCJ&FQQ&rVTQOQQQOQ&QLQ<K5QEKK&A7`K7mz_8Qx7Q|4QxQg[WLQRQOQGXQXVQC&rQKV[7QKp0QC>vXM(SQxS(r(|KQXQ>VQ6JQ\"`P`nXQOQOIBTQOQg[DHLQ}OQgXGQxQOKQrAH55Q7J[5PQQOKPQdgEQXX>5Q&Q[7QgSQ&V[Y[0VT2QRQO`QQOKxQqr8Q\"`Q0[5QQ(9QOWQ7QrQ[CRQr1WQQONQ8QQK2Q[`QQ}\"LQOC[7JQDQxQQO\"&A<0Q2QOQ<[ILGQ&EAQ5Q0GQRQ<[OQQVPQE6Q_2Q`Q&&AQQ<VQOMBQZEQ3QVQ&WQ\"&AQOQXDHXQQORQ5Qd_2Q7Q&`Q3QF[6Q&5Qx[3VTQQOQ[OHXQDQOQ&q&QRQOQgrQ[OQr[4QgXMQg|kqzjG[cd(kkk!ALMMEO&QE[F[VQZQOVTQE6QE[H`jZQ[JEKVPQJKEIB5Q:[OQXXMVBQ&rQQQ6Q1QQOQrQ3Q\"7QKMQ8Q5KQ7Qx[rxQOGQ[rpPQOEH[YQX]RQrXXKM_[F`[ODXX<PQr8QOJ[CSQzQOQNP[U1QQOK.nXVQQ[OQQgL[DICQQOD&iQO[UIIVTXQO`QK<_8Qx`[xZS`7}`}_2K2Qx|<|_2Q0F]Q?W[AQG&V8G>L<P_<6GC>PvS[2Q\"WQQOLQQOWQ2Q&RXXJQXRQMKQOQ4QVQ5Q[r5QzXQQO`QJ[pwQ_r0Q_4QVQKQ&5KQ}r7V9Q&YVQQ_4Q}QrQrH[_YQ528QC]KKQ&}PQQrdK:&Q[U9QJQOKVQJVQQOQ`QQQrwQ\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\"JULIET\",gen_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f61bf22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Butcniz,\n",
      "    They'll will have her even to you my woo'ful.\n",
      "    I crum'd uppers'd for her, sir; as the shame,\n",
      "    With all rose; be resistery.\n",
      "  BOLINGBROKE. Even his purse opposeth the bether\n",
      "    Turn with feast. This is a minut, monate.                Exeunt SENAMAN and a cried ot STUPYNINCE and Tybrows alight all now of them,\n",
      "    I'll empliam?\n",
      "  POLIXENES. I pray I have done; gentlemen-robbet?\n",
      "  HUBERT. Is any bold!\n",
      "  BEROWNE. Uplike it back. But thou lost not a fortune\n",
      "    And I cannot hence, sweethat looks.\n",
      "  PETRUCHIO. Sir, how shapes of it, if you keep you.  \n",
      "  ANTONY. We'll heard it me too thus tenny swe, King and thought\n",
      "    Than gives between A gotten begins!\n",
      "     When this is us thinks.\n",
      "    The general street, posain join'd off proud- good;\n",
      "    and my stumberlanching-strements may not be think\n",
      "    When Atroad, peasery, witness not for her and of you.\n",
      "  TAMORA. I bespech me, that is this purpos'd from mine e, sir,\n",
      "    To paint, moress, Opiniar, besheinds, but\n",
      "    frungm to eat hi\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\"But\",gen_size=1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
